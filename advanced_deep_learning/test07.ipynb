{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1CYPgoL3q5COOzE-XJSF-EEkZ29VTd3y5","authorship_tag":"ABX9TyN2c1jtpS/bnl9MByJ8WiVg"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["LSTM 실습"],"metadata":{"id":"IzjPBfQVKRDd"}},{"cell_type":"code","source":["!pip install Korpora"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":432},"id":"H8x-haLecxS_","executionInfo":{"status":"ok","timestamp":1744888352502,"user_tz":-540,"elapsed":2624,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"0c57afa3-89a1-41f9-8268-5f76709ba58d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting Korpora\n","  Downloading Korpora-0.2.0-py3-none-any.whl.metadata (26 kB)\n","Collecting dataclasses>=0.6 (from Korpora)\n","  Downloading dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (2.0.2)\n","Requirement already satisfied: tqdm>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (4.67.1)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (2.32.3)\n","Requirement already satisfied: xlrd>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from Korpora) (2.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20.0->Korpora) (2025.1.31)\n","Downloading Korpora-0.2.0-py3-none-any.whl (57 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Installing collected packages: dataclasses, Korpora\n","Successfully installed Korpora-0.2.0 dataclasses-0.6\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["dataclasses"]},"id":"24534d604db54475908c402529d3b15a"}},"metadata":{}}]},{"cell_type":"code","source":["! pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5ACBVc2rdhh0","executionInfo":{"status":"ok","timestamp":1744888545713,"user_tz":-540,"elapsed":2821,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"228ea9c7-7f51-4dd8-d39e-66692d892a1f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.3.2)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.2 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["from torch import nn\n","\n","\n","class SentenceClassifier(nn.Module):\n","    def __init__(\n","        self,\n","        n_vocab,\n","        hidden_dim,\n","        embedding_dim,\n","        n_layers,\n","        dropout=0.5,\n","        bidirectional=True,\n","        model_type=\"lstm\"\n","    ):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(\n","            num_embeddings=n_vocab,\n","            embedding_dim=embedding_dim,\n","            padding_idx=0\n","        )\n","        if model_type == \"rnn\":\n","            self.model = nn.RNN(\n","                input_size=embedding_dim,\n","                hidden_size=hidden_dim,\n","                num_layers=n_layers,\n","                bidirectional=bidirectional,\n","                dropout=dropout,\n","                batch_first=True,\n","            )\n","        elif model_type == \"lstm\":\n","            self.model = nn.LSTM(\n","            #implement_by_yourself\n","            )\n","\n","        if bidirectional:\n","            self.classifier = nn.Linear(hidden_dim * 2, 1)\n","        else:\n","            self.classifier = nn.Linear(hidden_dim, 1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, inputs):\n","        embeddings = self.embedding(inputs)\n","        output, _ = self.model(embeddings)\n","        last_output = output[:, -1, :]\n","        last_output = self.dropout(last_output)\n","        logits = self.classifier(last_output)\n","        return logits"],"metadata":{"id":"8lq9BXvIUAOh","executionInfo":{"status":"ok","timestamp":1744888373622,"user_tz":-540,"elapsed":1615,"user":{"displayName":"yam kk","userId":"06700488700849752406"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from Korpora import Korpora\n","\n","corpus = Korpora.load(\"nsmc\")\n","corpus_df = pd.DataFrame(corpus.test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajorvrr_cqIr","executionInfo":{"status":"ok","timestamp":1744888375592,"user_tz":-540,"elapsed":1968,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"3de1b5df-21b2-4c96-f085-c911c2ed8a64"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을\n","    손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다.\n","\n","    말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다.\n","    해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고,\n","    해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다.\n","\n","    # Description\n","    Author : e9t@github\n","    Repository : https://github.com/e9t/nsmc\n","    References : www.lucypark.kr/docs/2015-pyconkr/#39\n","\n","    Naver sentiment movie corpus v1.0\n","    This is a movie review dataset in the Korean language.\n","    Reviews were scraped from Naver Movies.\n","\n","    The dataset construction is based on the method noted in\n","    [Large movie review dataset][^1] from Maas et al., 2011.\n","\n","    [^1]: http://ai.stanford.edu/~amaas/data/sentiment/\n","\n","    # License\n","    CC0 1.0 Universal (CC0 1.0) Public Domain Dedication\n","    Details in https://creativecommons.org/publicdomain/zero/1.0/\n","\n"]},{"output_type":"stream","name":"stderr","text":["[nsmc] download ratings_train.txt: 14.6MB [00:00, 107MB/s]                             \n","[nsmc] download ratings_test.txt: 4.90MB [00:00, 55.4MB/s]\n"]}]},{"cell_type":"code","source":["train = corpus_df.sample(frac=0.9, random_state=42)\n","test = corpus_df.drop(train.index)\n","\n","print(train.head(5).to_markdown())\n","print(\"Training Data Size : \", len(train))\n","print(\"Testing Data Size : \", len(test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yV2rDLY4c_Mx","executionInfo":{"status":"ok","timestamp":1744888499505,"user_tz":-540,"elapsed":47,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"e78c366d-8551-452d-9198-29831deae9ee"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["|       | text                                                                                     |   label |\n","|------:|:-----------------------------------------------------------------------------------------|--------:|\n","| 33553 | 모든 편견을 날려 버리는 가슴 따뜻한 영화. 로버트 드 니로, 필립 세이모어 호프만 영원하라. |       1 |\n","|  9427 | 무한 리메이크의 소재. 감독의 역량은 항상 그 자리에...                                    |       0 |\n","|   199 | 신날 것 없는 애니.                                                                       |       0 |\n","| 12447 | 잔잔 격동                                                                                |       1 |\n","| 39489 | 오랜만에 찾은 주말의 명화의 보석                                                         |       1 |\n","Training Data Size :  45000\n","Testing Data Size :  5000\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Okt\n","from collections import Counter\n","\n","\n","def build_vocab(corpus, n_vocab, special_tokens):\n","    counter = Counter()\n","    for tokens in corpus:\n","        counter.update(tokens)\n","    vocab = special_tokens\n","    for token, count in counter.most_common(n_vocab):\n","        vocab.append(token)\n","    return vocab\n","\n","\n","tokenizer = Okt()\n","train_tokens = [tokenizer.morphs(review) for review in train.text]\n","test_tokens = [tokenizer.morphs(review) for review in test.text]\n","\n","vocab = build_vocab(corpus=train_tokens, n_vocab=5000, special_tokens=[\"<pad>\", \"<unk>\"])\n","token_to_id = {token: idx for idx, token in enumerate(vocab)}\n","id_to_token = {idx: token for idx, token in enumerate(vocab)}\n","\n","print(vocab[:10])\n","print(len(vocab))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EOvMKCWvc50y","executionInfo":{"status":"ok","timestamp":1744888811137,"user_tz":-540,"elapsed":142271,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"9f156127-fd8f-4ffa-e280-1804a7e9be2e"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["['<pad>', '<unk>', '.', '이', '영화', '의', '..', '가', '에', '...']\n","5002\n"]}]},{"cell_type":"code","source":["import numpy as np\n","\n","\n","def pad_sequences(sequences, max_length, pad_value):\n","    result = list()\n","    for sequence in sequences:\n","        sequence = sequence[:max_length]\n","        pad_length = max_length - len(sequence)\n","        padded_sequence = sequence + [pad_value] * pad_length\n","        result.append(padded_sequence)\n","    return np.asarray(result)\n","\n","\n","unk_id = token_to_id[\"<unk>\"]\n","train_ids = [[token_to_id.get(token, unk_id) for token in tokens] for tokens in train_tokens]\n","test_ids = [[token_to_id.get(token, unk_id) for token in tokens] for tokens in test_tokens]\n","\n","max_length = 32\n","pad_id = token_to_id[\"<pad>\"]\n","train_ids = pad_sequences(train_ids, max_length, pad_id)\n","test_ids = pad_sequences(test_ids, max_length, pad_id)\n","\n","print(train_ids[0])\n","print(test_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cFuoYpIKdoXd","executionInfo":{"status":"ok","timestamp":1744888816019,"user_tz":-540,"elapsed":573,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"de6b7591-65ba-4804-9c73-dd69d83300b9"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 223 1716   10 4036 2095  193  755    4    2 2330 1031  220   26   13\n"," 4839    1    1    1    2    0    0    0    0    0    0    0    0    0\n","    0    0    0    0]\n","[3307    5 1997  456    8    1 1013 3906    5    1    1   13  223   51\n","    3    1 4684    6    0    0    0    0    0    0    0    0    0    0\n","    0    0    0    0]\n"]}]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","\n","train_ids = torch.tensor(train_ids)\n","test_ids = torch.tensor(test_ids)\n","\n","train_labels = torch.tensor(train.label.values, dtype=torch.float32)\n","test_labels = torch.tensor(test.label.values, dtype=torch.float32)\n","\n","train_dataset = TensorDataset(train_ids, train_labels)\n","test_dataset = TensorDataset(test_ids, test_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"],"metadata":{"id":"l85G6YgDepIU","executionInfo":{"status":"ok","timestamp":1744888864291,"user_tz":-540,"elapsed":61,"user":{"displayName":"yam kk","userId":"06700488700849752406"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader\n","\n","\n","train_ids = torch.tensor(train_ids)\n","test_ids = torch.tensor(test_ids)\n","\n","train_labels = torch.tensor(train.label.values, dtype=torch.float32)\n","test_labels = torch.tensor(test.label.values, dtype=torch.float32)\n","\n","train_dataset = TensorDataset(train_ids, train_labels)\n","test_dataset = TensorDataset(test_ids, test_labels)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FO69UP0whaqP","executionInfo":{"status":"ok","timestamp":1744889558060,"user_tz":-540,"elapsed":26,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"ad886a89-4600-47d0-bed2-1356183c5505"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-13-981b453c1bb2>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  train_ids = torch.tensor(train_ids)\n","<ipython-input-13-981b453c1bb2>:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  test_ids = torch.tensor(test_ids)\n"]}]},{"cell_type":"code","source":["from torch import optim\n","\n","\n","n_vocab = len(token_to_id)\n","hidden_dim = 64\n","embedding_dim = 128\n","n_layers = 2\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","# SentenceClassifier의 RNN 계층에 input_size와 hidden_size를 명시적으로 전달 (이거 없으면 오류남)\n","class SentenceClassifier(nn.Module):\n","    def __init__(self, n_vocab, hidden_dim, embedding_dim, n_layers):\n","        super(SentenceClassifier, self).__init__()\n","\n","        self.embedding = nn.Embedding(n_vocab, embedding_dim)\n","\n","        # RNN (LSTM, GRU, RNN 등) 계층을 정의할 때 input_size와 hidden_size를 명시적으로 지정\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, n_layers, batch_first=True)\n","\n","        # Linear layer to output predictions (for binary classification)\n","        self.fc = nn.Linear(hidden_dim, 1)\n","\n","    def forward(self, x):\n","        x = self.embedding(x)  # Embedding lookup\n","        rnn_out, (hn, cn) = self.rnn(x)  # Pass through RNN\n","        out = self.fc(hn[-1])  # Use the last hidden state for classification\n","        return out\n","\n","# 모델을 device로 이동\n","classifier = SentenceClassifier(\n","    n_vocab=n_vocab, hidden_dim=hidden_dim, embedding_dim=embedding_dim, n_layers=n_layers\n",").to(device)\n","\n","criterion = nn.BCEWithLogitsLoss().to(device)\n","optimizer = optim.RMSprop(classifier.parameters(), lr=0.001)\n"],"metadata":{"id":"t9GQ4Ch9el58","executionInfo":{"status":"ok","timestamp":1744889768985,"user_tz":-540,"elapsed":11735,"user":{"displayName":"yam kk","userId":"06700488700849752406"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def train(model, datasets, criterion, optimizer, device, interval):\n","    model.train()\n","    losses = list()\n","\n","    for step, (input_ids, labels) in enumerate(datasets):\n","        input_ids = input_ids.to(device)\n","        labels = labels.to(device).unsqueeze(1)\n","\n","        logits = model(input_ids)\n","        loss = criterion(logits, labels)\n","        losses.append(loss.item())\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if step % interval == 0:\n","            print(f\"Train Loss {step} : {np.mean(losses)}\")\n","\n","\n","def test(model, datasets, criterion, device):\n","#implement_by_yourself\n","    losses = list()\n","    corrects = list()\n","\n","    for step, (input_ids, labels) in enumerate(datasets):\n","        input_ids = input_ids.to(device)\n","        labels = labels.to(device).unsqueeze(1)\n","\n","        logits = model(input_ids)\n","        loss = criterion(logits, labels)\n","        losses.append(loss.item())\n","        yhat = torch.sigmoid(logits)>.5\n","        corrects.extend(\n","            torch.eq(yhat, labels).cpu().tolist()\n","        )\n","\n","    print(f\"Val Loss : {np.mean(losses)}, Val Accuracy : {np.mean(corrects)}\")\n","\n","\n","epochs = 5\n","interval = 500\n","\n","for epoch in range(epochs):\n","    train(classifier, train_loader, criterion, optimizer, device, interval)\n","    test(classifier, test_loader, criterion, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RNNSHAJfEFp","executionInfo":{"status":"ok","timestamp":1744889866780,"user_tz":-540,"elapsed":43020,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"422a33c4-e5c8-49bf-962c-ba6d90f300a4"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Loss 0 : 0.695072591304779\n","Train Loss 500 : 0.6942265699961466\n","Train Loss 1000 : 0.6934678092464939\n","Train Loss 1500 : 0.6868932030146953\n","Train Loss 2000 : 0.67314980683596\n","Train Loss 2500 : 0.6513269522198674\n","Val Loss : 0.5264659732961046, Val Accuracy : 0.7374\n","Train Loss 0 : 0.472129225730896\n","Train Loss 500 : 0.49395283833592235\n","Train Loss 1000 : 0.48102078431255213\n","Train Loss 1500 : 0.4671100214729303\n","Train Loss 2000 : 0.45786401118593534\n","Train Loss 2500 : 0.4530734220822779\n","Val Loss : 0.42978942737030906, Val Accuracy : 0.7904\n","Train Loss 0 : 0.25338685512542725\n","Train Loss 500 : 0.36645899815652183\n","Train Loss 1000 : 0.3723138472982696\n","Train Loss 1500 : 0.37302251288209415\n","Train Loss 2000 : 0.3709449103695044\n","Train Loss 2500 : 0.370006916523933\n","Val Loss : 0.402672873875394, Val Accuracy : 0.8164\n","Train Loss 0 : 0.06260056048631668\n","Train Loss 500 : 0.32545281757792077\n","Train Loss 1000 : 0.31891196278425366\n","Train Loss 1500 : 0.3192355686911617\n","Train Loss 2000 : 0.3209589415382052\n","Train Loss 2500 : 0.32125602504376266\n","Val Loss : 0.392704284610078, Val Accuracy : 0.8208\n","Train Loss 0 : 0.4624101519584656\n","Train Loss 500 : 0.2732312924631996\n","Train Loss 1000 : 0.2726984904812915\n","Train Loss 1500 : 0.2746655017889535\n","Train Loss 2000 : 0.2757759190330664\n","Train Loss 2500 : 0.2760931759743524\n","Val Loss : 0.39456507087515563, Val Accuracy : 0.8158\n"]}]},{"cell_type":"code","source":["token_to_embedding = dict()\n","embedding_matrix = classifier.embedding.weight.detach().cpu().numpy()\n","\n","\n","for word, emb in zip(vocab, embedding_matrix):\n","    token_to_embedding[word] = emb\n","\n","token = vocab[1000]\n","print(token, token_to_embedding[token])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ot_SwBcgvsO","executionInfo":{"status":"ok","timestamp":1744889870801,"user_tz":-540,"elapsed":25,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"fc67597a-f647-4920-9b20-5abde0997155"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["보고싶다 [ 1.2281678   0.5951531   0.8368871  -1.2582477  -0.21166132 -0.24444482\n"," -0.80041087  0.5784702   1.1852795  -2.284814   -0.5792789  -0.69578683\n","  0.36382562 -0.36061493 -0.5280843   1.6539719  -1.8765484   0.67175335\n"," -0.4381631  -0.1244906  -0.86269766  0.54199785 -1.6591214   0.6722663\n"," -0.06841276 -3.0209486  -0.77700543 -0.7427915   0.85975164 -0.11472411\n","  0.10843823  0.4331702  -1.4378648   1.3076323  -1.5888231   0.29101256\n","  0.9465299   1.3309526   1.0852147   0.8541175  -0.11733964  0.01684624\n","  0.7594496  -1.3568968   0.59422773  3.2571535  -2.2038214   0.32962024\n"," -3.2169266   0.8866888   0.4844787  -0.54137707 -3.0739183  -0.450604\n","  1.3145851   0.75568086  0.47265688  0.4628807   0.08145277 -1.283338\n"," -1.2062603  -0.5635626  -0.59140134 -0.9127755  -0.4290772   0.78970844\n","  0.7395567  -1.5786835  -0.28760582 -0.18155266 -1.0984571  -1.7807245\n","  0.9532638  -0.9650262  -0.5225827  -1.458528   -1.6714634  -0.69187707\n","  1.752401   -0.70465314 -1.194816   -0.1827637   1.290949    1.0980434\n","  0.00431588 -0.39659813  0.24608228  0.5026808  -0.18589403 -0.01563243\n"," -0.5372254  -0.8887183   1.7387342  -0.35574314 -0.5167362  -0.91288275\n"," -0.32541934 -1.8551478   1.10287    -0.32162526  1.4624047   2.4629\n"," -1.2835134  -1.250198   -0.4550378  -0.52671784 -0.19650036  0.15183489\n","  0.6222036  -0.944707   -0.44806805 -0.56190765 -1.6132478  -0.34491813\n","  1.5932329  -2.5937438   1.1642861   0.00525192  0.1945117  -0.7964163\n","  0.41976425  1.1012357  -0.51273817 -1.1741768  -0.18719362 -0.3329145\n","  0.9164679   1.8253009 ]\n"]}]},{"cell_type":"markdown","source":["Transformer 실습\n","- 영어-독일어 번역 예제"],"metadata":{"id":"KWHTMlVFqC_Q"}},{"cell_type":"code","source":["!python -m spacy download de\n","!python -m spacy download en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MemlPTTCqKQI","executionInfo":{"status":"ok","timestamp":1744892193271,"user_tz":-540,"elapsed":17056,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"ddedff57-377d-4ce8-9d4f-e0c70f7ed962"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Please use the\n","full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n","Collecting de-core-news-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: de-core-news-sm\n","Successfully installed de-core-news-sm-3.8.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('de_core_news_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n","\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n","full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n","Collecting en-core-web-sm==3.8.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}]},{"cell_type":"code","source":["# Multi30k 데이터세트가 다운로드 되지 않고, Timeout 오류가 발생하는 경우, 다음 셀을 실행한다.\n","\n","from torchtext.datasets import multi30k\n","\n","\n","multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n","multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n","multi30k.URL[\"test\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/mmt16_task1_test.tar.gz\""],"metadata":{"id":"8Ryd-jTlraZ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch==2.3.0 torchtext==0.18.0 portalocker torchdata==0.9.0\n","from torchtext.datasets import Multi30k\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","\n","def generate_tokens(text_iter, language):\n","    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n","\n","    for text in text_iter:\n","        yield token_transform[language](text[language_index[language]])\n","\n","\n","SRC_LANGUAGE = \"de\"\n","TGT_LANGUAGE = \"en\"\n","UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n","special_symbols = [\"<unk>\", \"<pad>\", \"<bos>\", \"<eos>\"]\n","\n","token_transform = {\n","  SRC_LANGUAGE: get_tokenizer(\"spacy\", language=\"de_core_news_sm\"),\n","  TGT_LANGUAGE: get_tokenizer(\"spacy\", language=\"en_core_web_sm\")\n","}\n","\n","print(\"Token Transform:\")\n","print(token_transform)\n","\n","vocab_transform = {}\n","for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","  train_iter = Multi30k(split=\"train\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","  vocab_transform[language] = build_vocab_from_iterator(\n","      generate_tokens(train_iter, language),\n","      min_freq=1,\n","      specials=special_symbols,\n","      special_first=True\n","  )\n","\n","for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    vocab_transform[language].set_default_index(UNK_IDX)\n","\n","print(\"Vocab Transform:\")\n","print(vocab_transform)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjsjmF1Brima","executionInfo":{"status":"ok","timestamp":1744892579665,"user_tz":-540,"elapsed":218806,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"361c8dd3-e30f-49b4-b685-92e0c6e95f22"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torch==2.3.0\n","  Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchtext==0.18.0\n","  Downloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Collecting portalocker\n","  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n","Collecting torchdata==0.9.0\n","  Downloading torchdata-0.9.0-cp311-cp311-manylinux1_x86_64.whl.metadata (5.5 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (4.13.1)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.3.0) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.0)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.0)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.0)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.0)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.0)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.0)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.0)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.0)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.0 (from torch==2.3.0)\n","  Downloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (4.67.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (2.32.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.18.0) (2.0.2)\n","Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.9.0) (2.3.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.0) (12.5.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.3.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.18.0) (2025.1.31)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.3.0) (1.3.0)\n","Downloading torch-2.3.0-cp311-cp311-manylinux1_x86_64.whl (779.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.2/779.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchtext-0.18.0-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchdata-0.9.0-cp311-cp311-manylinux1_x86_64.whl (2.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n","Installing collected packages: triton, portalocker, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchtext, torchdata\n","  Attempting uninstall: triton\n","    Found existing installation: triton 3.2.0\n","    Uninstalling triton-3.2.0:\n","      Successfully uninstalled triton-3.2.0\n","  Attempting uninstall: nvidia-nvtx-cu12\n","    Found existing installation: nvidia-nvtx-cu12 12.4.127\n","    Uninstalling nvidia-nvtx-cu12-12.4.127:\n","      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.21.5\n","    Uninstalling nvidia-nccl-cu12-2.21.5:\n","      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.6.0+cu124\n","    Uninstalling torch-2.6.0+cu124:\n","      Successfully uninstalled torch-2.6.0+cu124\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\n","torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 portalocker-3.1.1 torch-2.3.0 torchdata-0.9.0 torchtext-0.18.0 triton-2.3.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchtext/datasets/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/usr/local/lib/python3.11/dist-packages/torchtext/data/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/usr/local/lib/python3.11/dist-packages/torchtext/vocab/__init__.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n","/usr/local/lib/python3.11/dist-packages/torchtext/utils.py:4: UserWarning: \n","/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n","Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n","  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"]},{"output_type":"stream","name":"stdout","text":["Token Transform:\n","{'de': functools.partial(<function _spacy_tokenize at 0x791f29f2db20>, spacy=<spacy.lang.de.German object at 0x791f1d180ed0>), 'en': functools.partial(<function _spacy_tokenize at 0x791f29f2db20>, spacy=<spacy.lang.en.English object at 0x791f1ad51d90>)}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n","################################################################################\n","WARNING!\n","The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n","future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n","to learn more and leave feedback.\n","################################################################################\n","\n","  deprecation_warning()\n"]},{"output_type":"stream","name":"stdout","text":["Vocab Transform:\n","{'de': Vocab(), 'en': Vocab()}\n"]}]},{"cell_type":"code","source":["import math\n","import torch\n","from torch import nn\n","\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, max_len, dropout=0.1):\n","        super().__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","        position = torch.arange(max_len).unsqueeze(1)\n","        div_term = torch.exp(\n","              torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n","        )\n","\n","        pe = torch.zeros(max_len, 1, d_model)\n","        pe[:, 0, 0::2] = torch.sin(position * div_term)\n","        pe[:, 0, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer(\"pe\", pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[: x.size(0)]\n","        return self.dropout(x)\n","\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size, emb_size):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(\n","        self,\n","        num_encoder_layers,\n","        num_decoder_layers,\n","        emb_size,\n","        max_len,\n","        nhead,\n","        src_vocab_size,\n","        tgt_vocab_size,\n","        dim_feedforward,\n","        dropout=0.1,\n","    ):\n","        super().__init__()\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(\n","            d_model=emb_size, max_len=max_len, dropout=dropout\n","        )\n","        self.transformer = nn.Transformer(\n","              d_model=emb_size,\n","              nhead=nhead,\n","              num_encoder_layers=num_encoder_layers,\n","              num_decoder_layers=num_decoder_layers,\n","              dim_feedforward=dim_feedforward,\n","              dropout=dropout,\n","        )\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","\n","    def forward(\n","        self,\n","        src,\n","        trg,\n","        src_mask,\n","        tgt_mask,\n","        src_padding_mask,\n","        tgt_padding_mask,\n","        memory_key_padding_mask,\n","    ):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        outs = self.transformer(\n","            src=src_emb,\n","            tgt=tgt_emb,\n","            src_mask=src_mask,\n","            tgt_mask=tgt_mask,\n","            memory_mask=None,\n","            src_key_padding_mask=src_padding_mask,\n","            tgt_key_padding_mask=tgt_padding_mask,\n","            memory_key_padding_mask=memory_key_padding_mask\n","        )\n","        return self.generator(outs)\n","\n","    def encode(self, src, src_mask):\n","        return self.transformer.encoder(\n","            self.positional_encoding(self.src_tok_emb(src)), src_mask\n","        )\n","\n","    def decode(self, tgt, memory, tgt_mask):\n","        return self.transformer.decoder(\n","            self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask\n","        )"],"metadata":{"id":"_EJnEFUZrr6T","executionInfo":{"status":"ok","timestamp":1744892584651,"user_tz":-540,"elapsed":49,"user":{"displayName":"yam kk","userId":"06700488700849752406"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torch import optim\n","\n","\n","BATCH_SIZE = 128\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","model = Seq2SeqTransformer(\n","      num_encoder_layers=3,\n","      num_decoder_layers=3,\n","      emb_size=512,\n","      max_len=512,\n","      nhead=8,\n","      src_vocab_size=len(vocab_transform[SRC_LANGUAGE]),\n","      tgt_vocab_size=len(vocab_transform[TGT_LANGUAGE]),\n","      dim_feedforward=512,\n",").to(DEVICE)\n","criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n","optimizer = optim.Adam(model.parameters())\n","\n","for main_name, main_module in model.named_children():\n","    print(main_name)\n","    for sub_name, sub_module in main_module.named_children():\n","        print(\"└\", sub_name)\n","        for ssub_name, ssub_module in sub_module.named_children():\n","            print(\"│  └\", ssub_name)\n","            for sssub_name, sssub_module in ssub_module.named_children():\n","                print(\"│  │  └\", sssub_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PrxUOYtPsvvl","executionInfo":{"status":"ok","timestamp":1744892596456,"user_tz":-540,"elapsed":4269,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"f54144db-6b59-4780-96b9-68eff02c93a8"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"]},{"output_type":"stream","name":"stdout","text":["src_tok_emb\n","└ embedding\n","tgt_tok_emb\n","└ embedding\n","positional_encoding\n","└ dropout\n","transformer\n","└ encoder\n","│  └ layers\n","│  │  └ 0\n","│  │  └ 1\n","│  │  └ 2\n","│  └ norm\n","└ decoder\n","│  └ layers\n","│  │  └ 0\n","│  │  └ 1\n","│  │  └ 2\n","│  └ norm\n","generator\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","\n","def sequential_transforms(*transforms):\n","    def func(txt_input):\n","        for transform in transforms:\n","            txt_input = transform(txt_input)\n","        return txt_input\n","    return func\n","\n","def input_transform(token_ids):\n","    return torch.cat(\n","        (torch.tensor([BOS_IDX]), torch.tensor(token_ids), torch.tensor([EOS_IDX]))\n","    )\n","\n","def collator(batch):\n","    src_batch, tgt_batch = [], []\n","    for src_sample, tgt_sample in batch:\n","        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n","        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n","\n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n","    return src_batch, tgt_batch\n","\n","\n","text_transform = {}\n","for language in [SRC_LANGUAGE, TGT_LANGUAGE]:\n","    text_transform[language] = sequential_transforms(\n","        token_transform[language], vocab_transform[language], input_transform\n","    )\n","\n","data_iter = Multi30k(split=\"valid\", language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","dataloader = DataLoader(\n","    data_iter,\n","    batch_size=BATCH_SIZE,\n","    collate_fn=collator\n",")\n","source_tensor, target_tensor = next(iter(dataloader))\n","\n","\n","print(\"(source, target):\")\n","print(next(iter(data_iter)))\n","\n","print(\"source_batch:\", source_tensor.shape)\n","print(source_tensor)\n","\n","print(\"target_batch:\", target_tensor.shape)\n","print(target_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TiwUGaGZs-3y","executionInfo":{"status":"ok","timestamp":1744893066737,"user_tz":-540,"elapsed":51,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"95c99db7-25c6-4e02-ded6-4cab436b7138"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["(source, target):\n","('Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen', 'A group of men are loading cotton onto a truck')\n","source_batch: torch.Size([35, 128])\n","tensor([[   2,    2,    2,  ...,    2,    2,    2],\n","        [  14,    5,    5,  ...,    5,   21,    5],\n","        [  38,   12,   35,  ...,   12, 1750,   69],\n","        ...,\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1]])\n","target_batch: torch.Size([30, 128])\n","tensor([[   2,    2,    2,  ...,    2,    2,    2],\n","        [   6,    6,    6,  ...,  250,   19,    6],\n","        [  39,   12,   35,  ...,   12, 3254,   61],\n","        ...,\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1],\n","        [   1,    1,    1,  ...,    1,    1,    1]])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n","  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"]}]},{"cell_type":"code","source":["def generate_square_subsequent_mask(s):\n","    mask = (torch.triu(torch.ones((s, s), device=DEVICE)) == 1).transpose(0, 1)\n","    mask = (\n","        mask.float()\n","        .masked_fill(mask == 0, float(\"-inf\"))\n","        .masked_fill(mask == 1, float(0.0))\n","    )\n","    return mask\n","\n","\n","def create_mask(src, tgt):\n","    src_seq_len = src.shape[0]\n","    tgt_seq_len = tgt.shape[0]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n","\n","    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n","    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\n","\n","target_input = target_tensor[:-1, :]\n","target_out = target_tensor[1:, :]\n","\n","source_mask, target_mask, source_padding_mask, target_padding_mask = create_mask(\n","    source_tensor, target_input\n",")\n","\n","print(\"source_mask:\", source_mask.shape)\n","print(source_mask)\n","print(\"target_mask:\", target_mask.shape)\n","print(target_mask)\n","print(\"source_padding_mask:\", source_padding_mask.shape)\n","print(source_padding_mask)\n","print(\"target_padding_mask:\", target_padding_mask.shape)\n","print(target_padding_mask)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yc0qeVV8tkG5","executionInfo":{"status":"ok","timestamp":1744893070999,"user_tz":-540,"elapsed":84,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"fcfdee29-7f5d-4168-c011-db7602994692"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["source_mask: torch.Size([35, 35])\n","tensor([[False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        ...,\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False],\n","        [False, False, False,  ..., False, False, False]], device='cuda:0')\n","target_mask: torch.Size([29, 29])\n","tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf, -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., -inf,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         -inf, -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., -inf, -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., -inf, -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., -inf, -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., -inf],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0.]], device='cuda:0')\n","source_padding_mask: torch.Size([128, 35])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        ...,\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n","target_padding_mask: torch.Size([128, 29])\n","tensor([[False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        ...,\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True],\n","        [False, False, False,  ...,  True,  True,  True]])\n"]}]},{"cell_type":"code","source":["def run(model, optimizer, criterion, split):\n","    model.train() if split == \"train\" else model.eval()\n","    data_iter = Multi30k(split=split, language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n","    dataloader = DataLoader(data_iter, batch_size=BATCH_SIZE, collate_fn=collator)\n","\n","    losses = 0\n","    for source_batch, target_batch in dataloader:\n","        source_batch = source_batch.to(DEVICE)\n","        target_batch = target_batch.to(DEVICE)\n","\n","        target_input = target_batch[:-1, :]\n","        target_output = target_batch[1:, :]\n","\n","        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(\n","            source_batch, target_input\n","        )\n","\n","        logits = model(\n","            src=source_batch,\n","            trg=target_input,\n","            src_mask=src_mask,\n","            tgt_mask=tgt_mask,\n","            src_padding_mask=src_padding_mask,\n","            tgt_padding_mask=tgt_padding_mask,\n","            memory_key_padding_mask=src_padding_mask,\n","        )\n","\n","        optimizer.zero_grad()\n","\n","        loss = criterion(\n","            logits.reshape(-1, logits.shape[-1]), target_output.reshape(-1)\n","        )\n","        if split == \"train\":\n","          loss.backward()\n","          optimizer.step()\n","        losses += loss.item()\n","\n","    return losses / len(list(dataloader))\n","\n","\n","for epoch in range(5):\n","    train_loss = run(model, optimizer, criterion, \"train\")\n","    val_loss = run(model, optimizer, criterion, \"valid\")\n","    print(f\"Epoch: {epoch+1}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jeJ4VMULtt1I","executionInfo":{"status":"ok","timestamp":1744893306065,"user_tz":-540,"elapsed":234223,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"40411221-852f-449e-bdfe-5801fdc824d3"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Train loss: 4.530, Val loss: 3.768\n","Epoch: 2, Train loss: 3.585, Val loss: 3.500\n","Epoch: 3, Train loss: 3.351, Val loss: 3.442\n","Epoch: 4, Train loss: 3.226, Val loss: 3.432\n","Epoch: 5, Train loss: 3.109, Val loss: 3.459\n"]}]},{"cell_type":"code","source":["def greedy_decode(model, source_tensor, source_mask, max_len, start_symbol):\n","    source_tensor = source_tensor.to(DEVICE)\n","    source_mask = source_mask.to(DEVICE)\n","\n","    memory = model.encode(source_tensor, source_mask)\n","    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n","    for i in range(max_len - 1):\n","        memory = memory.to(DEVICE)\n","        #implement_by_yourself\n","\n","        out = model.decode(ys, memory, target_mask)\n","        out = out.transpose(0, 1)\n","        prob = model.generator(out[:, -1])\n","        _, next_word = torch.max(prob, dim=1)\n","        next_word = next_word.item()\n","\n","        ys = torch.cat(\n","            [ys, torch.ones(1, 1).type_as(source_tensor.data).fill_(next_word)], dim=0\n","        )\n","        if next_word == EOS_IDX:\n","            break\n","    return ys\n","\n","\n","def translate(model, source_sentence):\n","    model.eval()\n","    source_tensor = text_transform[SRC_LANGUAGE](source_sentence).view(-1, 1)\n","    num_tokens = source_tensor.shape[0]\n","    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","    tgt_tokens = greedy_decode(\n","        model, source_tensor, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX\n","    ).flatten()\n","    output = vacab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))[1:-1]\n","    return \" \".join(output)\n","\n","\n","output_oov = translate(model, \"Eine Gruppe von Menschen steht vor einem Iglu .\")\n","output = translate(model, \"Eine Gruppe von Menschen steht vor einem Gebäude .\")\n","print(output_oov)\n","print(output)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":477},"id":"7v6cV_ect-yB","executionInfo":{"status":"error","timestamp":1744893306141,"user_tz":-540,"elapsed":86,"user":{"displayName":"yam kk","userId":"06700488700849752406"}},"outputId":"b9b2ab0c-8f11-4a45-e5e7-e6c661d686bf"},"execution_count":10,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The shape of the 2D attn_mask is torch.Size([29, 29]), but should be (1, 1).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-2e0f90fe8912>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0moutput_oov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Eine Gruppe von Menschen steht vor einem Iglu .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Eine Gruppe von Menschen steht vor einem Gebäude .\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_oov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-10-2e0f90fe8912>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(model, source_sentence)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnum_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msrc_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     tgt_tokens = greedy_decode(\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_symbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBOS_IDX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     ).flatten()\n","\u001b[0;32m<ipython-input-10-2e0f90fe8912>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[0;34m(model, source_tensor, source_mask, max_len, start_symbol)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#implement_by_yourself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-0c6296e495c5>\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, tgt, memory, tgt_mask)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         return self.transformer.decoder(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_tok_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             output = mod(output, memory, tgt_mask=tgt_mask,\n\u001b[0m\u001b[1;32m    495\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 890\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    891\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mha_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_is_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    897\u001b[0m     def _sa_block(self, x: Tensor,\n\u001b[1;32m    898\u001b[0m                   attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], is_causal: bool = False) -> Tensor:\n\u001b[0;32m--> 899\u001b[0;31m         x = self.self_attn(x, x, x,\n\u001b[0m\u001b[1;32m    900\u001b[0m                            \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m                            \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1267\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5380\u001b[0m             \u001b[0mcorrect_2d_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mcorrect_2d_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5382\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The shape of the 2D attn_mask is {attn_mask.shape}, but should be {correct_2d_size}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5383\u001b[0m             \u001b[0mattn_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5384\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The shape of the 2D attn_mask is torch.Size([29, 29]), but should be (1, 1)."]}]},{"cell_type":"code","source":[],"metadata":{"id":"N09-cR0-u1Rd"},"execution_count":null,"outputs":[]}]}